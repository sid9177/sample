import os
import streamlit as st
from openai import AzureOpenAI
import PyPDF2
import pandas as pd

# -----------------------------------------------------------------------------
# 1. AzureOpenAI Client Initialization
# -----------------------------------------------------------------------------
# Provide your real Azure OpenAI credentials here or use environment variables
client = AzureOpenAI(
    api_key=os.environ.get("AZURE_OPENAI_API_KEY", "YOUR_AZURE_OPENAI_API_KEY_HERE"),
    azure_endpoint=os.environ.get("AZURE_OPENAI_ENDPOINT", "https://YOUR_AZURE_OPENAI_ENDPOINT_HERE"),
    api_version="2024-05-01-preview",  # Example version; update if needed
)


# -----------------------------------------------------------------------------
# 2. Helper Functions
# -----------------------------------------------------------------------------

def extract_text_from_pdf(file) -> str:
    """Extract all text from a PDF file."""
    pdf_reader = PyPDF2.PdfReader(file)
    all_text = []
    for page in pdf_reader.pages:
        text = page.extract_text()
        if text:
            all_text.append(text)
    return "\n".join(all_text)


def extract_text_from_excel(file) -> str:
    """Extract text from all sheets in an Excel file as CSV strings."""
    xls = pd.ExcelFile(file)
    excel_text = []
    for sheet_name in xls.sheet_names:
        df = xls.parse(sheet_name)
        excel_text.append(df.to_csv(index=False))
    return "\n".join(excel_text)


def extract_text_from_csv(file) -> str:
    """Extract CSV content as a text string."""
    df = pd.read_csv(file)
    return df.to_csv(index=False)


def chat_with_azure_openai(client, conversation_history, new_user_message):
    """
    Send a chat completion request using the AzureOpenAI client.
    
    :param client: The AzureOpenAI client instance.
    :param conversation_history: A list of (role, content) tuples for the conversation so far.
    :param new_user_message: The latest user query string.
    :return: The model's response as a string.
    """
    # Build the list of message dicts:
    messages = [{"role": role, "content": content} for (role, content) in conversation_history]
    # Append the new user message
    messages.append({"role": "user", "content": new_user_message})

    # Create the chat completion
    response = client.create_chat_completion(
        engine="Cata-GPT4-o",  # or your actual deployment/model name
        messages=messages,
        temperature=0.7,
    )

    # Extract the assistant's reply
    assistant_message = response["choices"][0]["message"]["content"]
    return assistant_message


# -----------------------------------------------------------------------------
# 3. Streamlit Application
# -----------------------------------------------------------------------------
def main():
    st.title("GenAI Scorecard Metrics Data QA Chatbot (AzureOpenAI)")

    # Store conversation and file texts in Session State
    if "conversation_history" not in st.session_state:
        st.session_state.conversation_history = [
            ("system", "You are a helpful assistant answering questions about the policy, methodology, formulas, and CSV data.")
        ]

    if "policy_text" not in st.session_state:
        st.session_state.policy_text = None
    if "methodology_text" not in st.session_state:
        st.session_state.methodology_text = None
    if "formula_text" not in st.session_state:
        st.session_state.formula_text = None
    if "csv_text" not in st.session_state:
        st.session_state.csv_text = None

    # Step 1: Upload Policy PDF
    if not st.session_state.policy_text:
        st.subheader("Step 1: Upload Policy PDF")
        policy_file = st.file_uploader("Upload Policy PDF", type=["pdf"], key="policy_file")
        if policy_file is not None:
            st.session_state.policy_text = extract_text_from_pdf(policy_file)
            st.success("Policy PDF uploaded and processed!")
            st.write("Proceed to Step 2.")
        else:
            st.stop()

    # Step 2: Upload Methodology PDF
    if not st.session_state.methodology_text:
        st.subheader("Step 2: Upload Methodology PDF")
        methodology_file = st.file_uploader("Upload Methodology PDF", type=["pdf"], key="methodology_file")
        if methodology_file is not None:
            st.session_state.methodology_text = extract_text_from_pdf(methodology_file)
            st.success("Methodology PDF uploaded and processed!")
            st.write("Proceed to Step 3.")
        else:
            st.stop()

    # Step 3: Upload Formula Excel
    if not st.session_state.formula_text:
        st.subheader("Step 3: Upload Formula Excel")
        formula_file = st.file_uploader("Upload Formula Excel", type=["xls", "xlsx"], key="formula_file")
        if formula_file is not None:
            st.session_state.formula_text = extract_text_from_excel(formula_file)
            st.success("Formula Excel uploaded and processed!")
            st.write("Proceed to Step 4.")
        else:
            st.stop()

    # Step 4: Upload CSV Data
    if not st.session_state.csv_text:
        st.subheader("Step 4: Upload CSV file")
        csv_file = st.file_uploader("Upload CSV Data", type=["csv"], key="csv_file")
        if csv_file is not None:
            st.session_state.csv_text = extract_text_from_csv(csv_file)
            st.success("CSV uploaded and processed!")
            st.write("All documents uploaded. Start chatting below.")
        else:
            st.stop()

    # Combine all documents into one big reference text
    combined_documents_text = (
        f"Policy Document:\n{st.session_state.policy_text}\n\n"
        f"Methodology Document:\n{st.session_state.methodology_text}\n\n"
        f"Formula Document:\n{st.session_state.formula_text}\n\n"
        f"CSV Data:\n{st.session_state.csv_text}"
    )

    # Update the system message with context
    context_message = (
        "You have the following documents as reference:\n"
        + combined_documents_text
        + "\nAnswer questions based on these documents. "
          "If unsure and it's not in the documents, say you don't know."
    )

    st.session_state.conversation_history[0] = (
        "system",
        "You are a helpful assistant with knowledge of the policy, methodology, formulas, and CSV data. "
        f"Use the following context:\n{context_message}"
    )

    # Chat interface
    st.subheader("Chat with your Scorecard QA Bot")

    user_input = st.text_input("Ask a question about the policy, methodology, formulas, or the CSV data:")
    if st.button("Send") and user_input.strip():
        assistant_reply = chat_with_azure_openai(
            client,
            st.session_state.conversation_history,
            user_input
        )
        # Update session state with the conversation
        st.session_state.conversation_history.append(("user", user_input))
        st.session_state.conversation_history.append(("assistant", assistant_reply))

    # Display conversation history
    for role, content in st.session_state.conversation_history:
        if role == "assistant":
            st.markdown(f"**Assistant**: {content}")
        elif role == "user":
            st.markdown(f"**You**: {content}")

if __name__ == "__main__":
    main()
